#!/usr/bin/env python
"""
é…å¯¹äº¤æ˜“ç­›é€‰å™¨ - å¿«é€Ÿæµ‹è¯•è„šæœ¬
"""

import sys
from pathlib import Path
from datetime import datetime, timedelta

ROOT = Path(__file__).resolve().parent
if str(ROOT) not in sys.path:
    sys.path.append(str(ROOT))

from app.pairs_screener import PairsScreener


def test_basic_workflow():
    """æµ‹è¯•åŸºç¡€å·¥ä½œæµ"""
    print("\n" + "="*70)
    print("æµ‹è¯• 1: åŸºç¡€å·¥ä½œæµï¼ˆä½¿ç”¨5åªé“¶è¡Œè‚¡ï¼Œ180å¤©æ•°æ®ï¼‰")
    print("="*70)
    
    # ä½¿ç”¨5åªä¸»è¦é“¶è¡Œè‚¡
    codes = ['601398', '601939', '601288', '601166', '601328']
    
    # è®¾ç½®æ—¥æœŸ
    end_date = datetime.now()
    start_date = end_date - timedelta(days=180)
    
    start_str = start_date.strftime("%Y%m%d")
    end_str = end_date.strftime("%Y%m%d")
    
    print(f"\n[DATA] æµ‹è¯•å‚æ•°:")
    print(f"  - è‚¡ç¥¨: {', '.join(codes)} (å…±{len(codes)}åª)")
    print(f"  - æ—¥æœŸ: {start_str} ~ {end_str}")
    print(f"  - PCAæˆåˆ†: 15")
    print(f"  - DBSCAN eps: 0.5")
    
    try:
        screener = PairsScreener(start_str, end_str)
        results = screener.run(codes, eps=0.5, n_components=15)
        
        pairs_df = results['pairs']
        labels = results['labels']
        
        print(f"\n[PASS] æµ‹è¯•æˆåŠŸï¼")
        print(f"  - æ‰¾åˆ° {len(pairs_df)} å¯¹åæ•´é…å¯¹")
        print(f"  - èšç±»æ•°: {len(set(labels)) - (1 if -1 in labels else 0)}")
        print(f"  - å™ªéŸ³ç‚¹: {list(labels).count(-1)}")
        
        if len(pairs_df) > 0:
            print(f"\nğŸ† Top 3 é…å¯¹:")
            for i, (idx, row) in enumerate(pairs_df.head(3).iterrows(), 1):
                print(f"  {i}. {row['stock_a']} â†”ï¸ {row['stock_b']}")
                print(f"     ç›¸å…³ç³»æ•°: {row['correlation']:.4f}, På€¼: {row['coint_pvalue']:.6f}")
        
        return True
    
    except Exception as e:
        print(f"\n[FAIL] æµ‹è¯•å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return False


def test_parameter_sensitivity():
    """æµ‹è¯•å‚æ•°æ•æ„Ÿæ€§"""
    print("\n" + "="*70)
    print("æµ‹è¯• 2: å‚æ•°æ•æ„Ÿæ€§ï¼ˆä¸åŒepså€¼çš„å½±å“ï¼‰")
    print("="*70)
    
    codes = ['601398', '601939', '601288', '601166', '601328']
    
    end_date = datetime.now()
    start_date = end_date - timedelta(days=180)
    
    start_str = start_date.strftime("%Y%m%d")
    end_str = end_date.strftime("%Y%m%d")
    
    eps_values = [0.3, 0.5, 0.7]
    
    print(f"\næµ‹è¯•ä¸åŒçš„ eps å€¼å¯¹èšç±»çš„å½±å“:")
    
    try:
        screener = PairsScreener(start_str, end_str)
        
        for eps in eps_values:
            print(f"\n  eps={eps}:", end=" ")
            results = screener.run(codes, eps=eps, n_components=15)
            
            labels = results['labels']
            pairs_count = len(results['pairs'])
            
            n_clusters = len(set(labels)) - (1 if -1 in labels else 0)
            print(f"ç°‡æ•°={n_clusters}, é…å¯¹={pairs_count}")
        
        print(f"\n[PASS] å‚æ•°æ•æ„Ÿæ€§æµ‹è¯•å®Œæˆ")
        return True
    
    except Exception as e:
        print(f"\n[FAIL] æµ‹è¯•å¤±è´¥: {str(e)}")
        return False


def test_data_integrity():
    """æµ‹è¯•æ•°æ®å®Œæ•´æ€§"""
    print("\n" + "="*70)
    print("æµ‹è¯• 3: æ•°æ®å®Œæ•´æ€§")
    print("="*70)
    
    codes = ['601398', '601939', '601288']
    
    end_date = datetime.now()
    start_date = end_date - timedelta(days=180)
    
    start_str = start_date.strftime("%Y%m%d")
    end_str = end_date.strftime("%Y%m%d")
    
    print(f"\næ£€æŸ¥æ•°æ®è´¨é‡:")
    
    try:
        screener = PairsScreener(start_str, end_str)
        
        # è·å–æ•°æ®
        print(f"  1. è·å–è‚¡ç¥¨æ•°æ®...", end=" ")
        price_df = screener.fetch_stock_data(codes)
        print(f"[OK] ({price_df.shape[0]}è¡Œ Ã— {price_df.shape[1]}åˆ—)")
        
        # è®¡ç®—æ”¶ç›Šç‡
        print(f"  2. è®¡ç®—æ”¶ç›Šç‡...", end=" ")
        returns_df = screener.compute_returns(price_df)
        print(f"[OK] ({returns_df.shape[0]}è¡Œ Ã— {returns_df.shape[1]}åˆ—)")
        
        # æ£€æŸ¥ç¼ºå¤±å€¼
        missing_pct = returns_df.isna().sum().sum() / (returns_df.shape[0] * returns_df.shape[1]) * 100
        print(f"  3. ç¼ºå¤±å€¼æ£€æŸ¥: {missing_pct:.2f}%", end=" ")
        print("[OK]" if missing_pct < 1 else "âš ï¸")
        
        # PCA
        print(f"  4. PCAé™ç»´...", end=" ")
        X_pca, pca = screener.perform_pca(returns_df, n_components=10)
        explained_var = pca.explained_variance_ratio_.sum()
        print(f"[OK] (è§£é‡Šæ–¹å·®: {explained_var:.1%})")
        
        # DBSCAN
        print(f"  5. DBSCANèšç±»...", end=" ")
        labels = screener.perform_dbscan(X_pca, eps=0.5)
        n_clusters = len(set(labels)) - (1 if -1 in labels else 0)
        print(f"[OK] ({n_clusters}ä¸ªç°‡)")
        
        print(f"\n[PASS] æ•°æ®å®Œæ•´æ€§æµ‹è¯•é€šè¿‡")
        return True
    
    except Exception as e:
        print(f"\n[FAIL] æµ‹è¯•å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return False


def main():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("\n" + "="*70)
    print("Aè‚¡é…å¯¹äº¤æ˜“ç­›é€‰å™¨ - åŠŸèƒ½æµ‹è¯•")
    print("="*70)
    
    results = []
    
    # è¿è¡Œæµ‹è¯•
    results.append(("æ•°æ®å®Œæ•´æ€§", test_data_integrity()))
    results.append(("åŸºç¡€å·¥ä½œæµ", test_basic_workflow()))
    results.append(("å‚æ•°æ•æ„Ÿæ€§", test_parameter_sensitivity()))
    
    # æ€»ç»“
    print("\n" + "="*70)
    print("æµ‹è¯•æ€»ç»“")
    print("="*70)
    
    for test_name, passed in results:
        status = "[PASS] é€šè¿‡" if passed else "[FAIL] å¤±è´¥"
        print(f"{test_name}: {status}")
    
    all_passed = all(result[1] for result in results)
    
    print("\n" + "="*70)
    if all_passed:
        print("[PASS] æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼ç¨‹åºå¯æ­£å¸¸ä½¿ç”¨ã€‚")
    else:
        print("[FAIL] éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯ã€‚")
    print("="*70 + "\n")
    
    return 0 if all_passed else 1


if __name__ == '__main__':
    sys.exit(main())


