import os
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.messages import AIMessage, HumanMessage
from langchain_openai import ChatOpenAI
import streamlit as st
from app.state import AgentState
from app.ui_utils import render_live_timer, display_token_usage
from app.config import Config

# Simple in-memory cache for planner decisions to speed up repeated states
_planner_cache = {}

# Cache for ambiguity judgments to avoid repeated LLM calls on the same text
_ambig_cache = {}

def planner_agent(state: AgentState):
    """
    Supervisor agent that plans the workflow and reflects on results.
    Three-tier flow:
    1) Hard bypass when user forces a specific agent (no LLM calls).
    2) deepseek-chat for intent + complexity check; simple paths use fast heuristics.
    3) deepseek-reasoner plans only when the task is classified as complex.
    """
    print("--- PLANNER AGENT ---")
    # LLM settings (provider can be set via env; default in Config)
    provider = state.get("llm_provider") or Config.LLM_PROVIDER
    settings = Config.get_llm_settings(provider)
    planner_api_key = settings.get("api_key")
    planner_base = settings.get("base_url")
    planner_model = settings.get("model")

    def make_llm(model_override=None, temperature: float = 0, max_tokens=None):
        return ChatOpenAI(
            model=model_override or planner_model,
            api_key=planner_api_key,
            base_url=planner_base,
            temperature=temperature,
            max_tokens=max_tokens,
        )

    # Manual override: allow upstream to force a specific agent
    force_agent = state.get("force_agent")

    # Gather Context early for classification
    messages = state.get("messages", [])
    user_input = ""
    if messages:
        # Prefer the most recent human instruction to reflect the latest request context
        for message in reversed(messages):
            if isinstance(message, HumanMessage):
                user_input = message.content
                break
        if not user_input and messages:
            user_input = messages[-1].content

    # Ambiguity check: focus on missing action/intent (not ticker suffix). Skip when force_agent already set.
    def is_ambiguous(text: str) -> bool:
        if not text:
            return True
        stripped = text.strip()
        if len(stripped) == 0:
            return True

        # allow explicit slash agent commands to pass through
        if stripped.startswith("/"):
            return False

        cache_key = stripped.lower()
        if cache_key in _ambig_cache:
            return _ambig_cache[cache_key]

        # Heuristics: short, no verb/action, or conflicting multi-intent without priority
        action_keywords = [
            "è¡Œæƒ…", "ä»·æ ¼", "æ”¶ç›˜", "åˆ†æ—¶", "Kçº¿", "èµ°åŠ¿", "æŒ‡æ ‡", "å‡çº¿", "RSI", "MACD",
            "å›æµ‹", "ç­–ç•¥", "ä»£ç ", "æ‰§è¡Œ", "äº¤æ˜“", "ä¸‹å•",
            "ä¼°å€¼", "åˆ†ä½", "ä¾¿å®œ", "è´µ", "æ€§ä»·æ¯”",
            "å®è§‚", "ç‚¹è¯„",
            "è´¢æŠ¥", "å¹´æŠ¥", "å­£æŠ¥", "åŸºæœ¬é¢", "å¸‚å€¼", "pe", "pb", "roe", "è¥æ”¶", "å‡€åˆ©"
        ]

        lt = stripped.lower()
        has_action_kw = any(kw in lt for kw in action_keywords)
        too_short = len(stripped) < 8
        # conflicting intents: mentions both å›æµ‹/ç­–ç•¥ and ä¼°å€¼; or only says çœ‹çœ‹/åˆ†æ without object
        conflict = ("å›æµ‹" in stripped and ("ä¼°å€¼" in stripped or "åˆ†ä½" in stripped))
        no_action = not has_action_kw
        heuristic_ambig = too_short or no_action or conflict

        # LLM confirmation (short, deterministic)
        clf_prompt = ChatPromptTemplate.from_messages([
            ("system", "Decide if the user request is clear about WHAT ACTION to perform on the ticker(s). Reply with 'clear' or 'ambiguous' only."),
            ("user", "{text}")
        ])

        is_ambig = heuristic_ambig
        try:
            clf_llm = make_llm(max_tokens=2)
            resp = (clf_prompt | clf_llm).invoke({"text": stripped[:400]})
            result = (resp.content or "").strip().lower()
            is_ambig = heuristic_ambig or (result != "clear")
        except Exception:
            pass

        _ambig_cache[cache_key] = is_ambig
        return is_ambig

    # When caller already forced an agent (e.g., /data 000001.SZ), skip ambiguity asks.
    if not force_agent and is_ambiguous(user_input):
        clarification = "ä½ æƒ³å¯¹è¿™åªæ ‡çš„åšä»€ä¹ˆï¼Ÿç¤ºä¾‹ï¼š`/data 600519.SH æŸ¥çœ‹è¡Œæƒ…`ï¼Œ`å›æµ‹ 600519.SH åŒå‡çº¿ç­–ç•¥`ï¼Œ`ä¼°å€¼ 600519.SH å½“å‰åˆ†ä½`ã€‚å¦‚åªæƒ³çœ‹ä»·æ ¼å¯ç›´æ¥å›å¤ `/data 600519.SH`ã€‚"
        reasoning_text = "ç¼ºå°‘å…·ä½“æ“ä½œæ„å›¾ï¼Œéœ€è¦ç¡®è®¤æ˜¯è¡Œæƒ…/å›æµ‹/ä¼°å€¼/å®è§‚/è´¢æŠ¥ç­‰å“ªç±»è¯·æ±‚ã€‚"
        try:
            ambig_prompt = ChatPromptTemplate.from_messages([
                ("system", """ä½ éœ€è¦è¯´æ˜ä¸ºä½•è¦æ¾„æ¸…ï¼Œå¹¶ç»™å‡ºç®€çŸ­æ¾„æ¸…é—®é¢˜ã€‚ä¸¥æ ¼è¾“å‡ºä¸¤è¡Œï¼š
Reasoning: <ç®€æ´ä¸­æ–‡ï¼Œè¯´æ˜ç¼ºå°‘å…·ä½“æ“ä½œ/æ„å›¾>
Clarification: <ä¸­æ–‡æ¾„æ¸…æé—®ï¼Œç»™å‡º 2-3 ä¸ªç¤ºä¾‹ï¼Œè¦†ç›–è¡Œæƒ…/å›æµ‹/ä¼°å€¼ ç­‰ï¼Œå¦‚ /data 600519.SH>
"""),
                ("user", "{text}")
            ])
            ambig_llm = make_llm(max_tokens=80)
            resp = (ambig_prompt | ambig_llm).invoke({"text": user_input[:400]})
            content = (resp.content or "").strip()
            if "Clarification:" in content:
                head, tail = content.split("Clarification:", 1)
                reasoning_text = head.replace("Reasoning:", "").strip() or reasoning_text
                clarification = tail.strip() or clarification
            else:
                reasoning_text = content or reasoning_text
        except Exception:
            pass
        return {
            "next_step": "FINISH",
            "retry_count": state.get("retry_count", 0),
            "sender": "planner_agent",
            "reasoning": reasoning_text,
            "analysis_completed": state.get("analysis_completed"),
            "analysis_runs": state.get("analysis_runs", 0),
            "force_agent": None,
            "need_disambiguation": True,
            "messages": [AIMessage(content=clarification)],
            "llm_interaction": {
                "input": {"ambiguous": True, "user_input": user_input},
                "prompt": "<ambiguous guard>",
                "response": clarification
            }
        }

    # Allow inline agent markers in the prompt (fallback in case frontend did not set force_agent)
    if not force_agent and user_input:
        marker_map = {
            "/data": "data_agent",
            "/quant": "quant_agent",
            "/exec": "exec_agent",
            "/analyst": "analyst_agent",
            "/macro": "macro_agent",
            "/valuation": "valuation_agent",
            "data_agent": "data_agent",
            "quant_agent": "quant_agent",
            "exec_agent": "exec_agent",
            "analyst_agent": "analyst_agent",
            "macro_agent": "macro_agent",
            "valuation_agent": "valuation_agent",
        }
        lower_text = user_input.strip().lower()
        for marker, agent in marker_map.items():
            if lower_text.startswith(marker):
                force_agent = agent
                break

    # Cheap, no-LLM flag detection for bypass scenarios
    def heuristic_flags(text: str):
        if not text:
            return False, False
        lt = text.lower()
        need_full = any(k in lt for k in ["all history", "full history", "entire history", "å…¨å†å²", "å…¨éƒ¨å†å²", "å…¨é‡" ])
        need_bench = any(k in lt for k in ["benchmark", "bench", "å¯¹æ¯”", "ç›¸å¯¹", "è¶…é¢", "åŸºå‡†", "æŒ‡æ•°"])
        return need_full, need_bench

    # Tier 1: short-circuit on forced agent BEFORE any LLM calls
    if force_agent in {"data_agent", "quant_agent", "exec_agent", "analyst_agent", "macro_agent", "valuation_agent"}:
        need_full_history_flag, needs_benchmark_flag = heuristic_flags(user_input)
        flag_payload = {
            "need_full_history": need_full_history_flag,
            "needs_benchmark": needs_benchmark_flag,
        }
        reasoning = f"æ”¶åˆ°ç›´æ¥è°ƒç”¨æŒ‡ä»¤ï¼Œè½¬äº¤ {force_agent}ã€‚"
        return {
            "next_step": force_agent,
            "retry_count": state.get("retry_count", 0),
            "sender": "planner_agent",
            "reasoning": reasoning,
            "analysis_completed": state.get("analysis_completed"),
            "analysis_runs": state.get("analysis_runs", 0),
            "force_agent": None,  # clear override after one hop
            **flag_payload,
            "llm_interaction": {
                "input": {"force_agent": force_agent},
                "prompt": "<skipped - forced agent>",
                "response": "<forced>"
            }
        }

    # Lightweight LLM extraction for flags (full history / benchmark) to avoid keyword explosion
    def extract_flags(text: str):
        if not text:
            return False, False
        flag_prompt = ChatPromptTemplate.from_messages([
            ("system", "You extract booleans for data needs. Reply with two lines exactly: full_history: yes/no ; benchmark: yes/no. Decide if the user wants ALL history (full/entire/å…¨éƒ¨) and whether a benchmark/comparison is requested (å¯¹æ¯”/è¶…é¢/ç›¸å¯¹/benchmark)."),
            ("user", "{text}")
        ])
        clf_llm = ChatOpenAI(
            model="deepseek-chat",
            api_key=planner_api_key,
            base_url=planner_base,
            temperature=0,
            max_tokens=10,
        )
        try:
            resp = (flag_prompt | clf_llm).invoke({"text": text[:400]})
            out = resp.content.lower()
            full = "full_history: yes" in out or "full_history: true" in out
            bench = "benchmark: yes" in out or "benchmark: true" in out
            return full, bench
        except Exception:
            return False, False

    need_full_history_flag, needs_benchmark_flag = extract_flags(user_input)
    flag_payload = {
        "need_full_history": need_full_history_flag,
        "needs_benchmark": needs_benchmark_flag,
    }

    # Keep legacy interpret hook (default off). Future: move to LLM signals.
    interpret_request = False

    # Direct short-circuit if force_agent provided
    if force_agent in {"data_agent", "quant_agent", "exec_agent", "analyst_agent", "macro_agent", "valuation_agent"}:
        reasoning = f"æ”¶åˆ°ç›´æ¥è°ƒç”¨æŒ‡ä»¤ï¼Œè½¬äº¤ {force_agent}ã€‚"
        return {
            "next_step": force_agent,
            "retry_count": state.get("retry_count", 0),
            "sender": "planner_agent",
            "reasoning": reasoning,
            "analysis_completed": state.get("analysis_completed"),
            "analysis_runs": state.get("analysis_runs", 0),
            "force_agent": None,  # clear override after one hop
            **flag_payload,
            "llm_interaction": {
                "input": {"force_agent": force_agent},
                "prompt": "<skipped - forced agent>",
                "response": "<forced>"
            }
        }

    # Helper: intent classification
    def classify_intent(user_text: str) -> str:
        """Return one of: data_query, quant_strategy, macro, valuation, news_info, other."""
        if not user_text:
            return "other"
        intent_prompt = ChatPromptTemplate.from_messages([
            (
                "system",
                """
You are a fast, deterministic intent classifier for a quant assistant. Output exactly one label from this set (lowercase):
- data_query     # å•æ ‡çš„è¡Œæƒ…/æŒ‡æ ‡/èµ°åŠ¿/ç®€å•åˆ†æ/è·å–æ•°æ®
 - data_query     # å•æ ‡çš„è¡Œæƒ…/æŒ‡æ ‡/èµ°åŠ¿/ç®€å•åˆ†æ/è·å–æ•°æ®/åŸºç¡€é¢ç®€æï¼ˆå¸‚å€¼/PE/PB/ROE/è¥æ”¶/å‡€åˆ©/è´¢æŠ¥æ‘˜å–ï¼‰
- quant_strategy # å›æµ‹/ç­–ç•¥/æŒ‡æ ‡/ç»„åˆ/ä»“ä½/è°ƒä»“/é£é™©æ§åˆ¶/å›æµ‹ä»£ç /æ‰§è¡Œç­–ç•¥
- macro          # å®è§‚ç»æµ/åˆ©ç‡/é€šèƒ€/å¢é•¿/æµåŠ¨æ€§/ä¿¡ç”¨/æ±‡ç‡/å®è§‚äº‹ä»¶è§£è¯»
- valuation      # ä¼°å€¼/æ€§ä»·æ¯”/ç›¸å¯¹ä½ç½®/åˆ†ä½/ä¾¿å®œè´µ/ä¼°å€¼ä¸æ”¶ç›Šå¯¹æ¯”/ä¼°å€¼åˆ†ä½
- news_info      # èµ„è®¯/æ–°é—»/äº‹ä»¶/å…¬å‘Š/å®è§‚æ¶ˆæ¯ç±»æŸ¥è¯¢
- other          # ä»¥ä¸Šå‡ä¸åŒ¹é…

Few-shot guidance:
Q: è·å–ä¸­å›½å¹³å®‰601318.SHçš„æ”¶ç›˜ä»·
A: data_query
Q: å¯¹ 600519.SH åšåŒå‡çº¿å›æµ‹ï¼ŒMA5>MA20 è¿›åœº
A: quant_strategy
Q: ç®€è¦ç‚¹è¯„å½“å‰å®è§‚æµåŠ¨æ€§
A: macro
Q: è¯„ä¼° 300750.SZ å½“å‰ä¼°å€¼åˆ†ä½
A: valuation
Q: ä»Šå¤©æœ‰æ— ç¾è”å‚¨ç›¸å…³æ–°é—»
A: news_info
Q: çœ‹çœ‹ 300750.SZ çš„å¸‚å€¼å’ŒPE
A: data_query
Q: æ‘˜è¦ 300750.SZ æœ€è¿‘ä¸€å­£è´¢æŠ¥ï¼Œç»™å…³é”®æŒ‡æ ‡
A: data_query
Q: 588000 ä¼°å€¼ç®—è´µå—ï¼Œåˆ†ä½åœ¨å“ª
A: valuation
Q: 588000 åšåŒå‡çº¿å›æµ‹
A: quant_strategy
Q: å¸®æˆ‘å†™ä¸€é¦–è¯—
A: other

Reply with the label only.
"""
            ),
            ("user", "{text}")
        ])
        clf_llm = make_llm(max_tokens=6)
        try:
            resp = (intent_prompt | clf_llm).invoke({"text": user_text[:400]})
            label = resp.content.strip().lower()
            if "data" in label:
                return "data_query"
            if "strategy" in label or "quant" in label or "ç»„åˆ" in label or "ç­–ç•¥" in label:
                return "quant_strategy"
            if "macro" in label or "å®è§‚" in label:
                return "macro"
            if "valuation" in label or "ä¼°å€¼" in label or "æ€§ä»·æ¯”" in label or "åˆ†ä½" in label:
                return "valuation"
            if "news" in label or "info" in label or "èµ„è®¯" in label or "æ–°é—»" in label:
                return "news_info"
            return "other"
        except Exception:
            return "other"

    intent_label = classify_intent(user_input)

    # Helper: quick classification to decide if task is complex (Tier 2 => choose chat vs reasoner)
    def is_complex_task(user_text: str) -> bool:
        if not user_text:
            return False
        clf_prompt = ChatPromptTemplate.from_messages([
            ("system", "You are a fast task classifier. Reply with 'simple' or 'complex' only."),
            ("user", "Classify the task: {task}")
        ])
        clf_llm = make_llm(max_tokens=4)
        try:
            resp = (clf_prompt | clf_llm).invoke({"task": user_text[:400]})
            text = resp.content.strip().lower()
            return any(k in text for k in ["complex", "å¤æ‚"])
        except Exception:
            return False

    complex_flag = is_complex_task(user_input)
    allow_fastpath = not complex_flag  # simple tasks take deterministic shortcuts; complex tasks defer to planner LLM
    # Use a heavier model only if provider is deepseek and marked complex; otherwise use provider default.
    planner_model_name = "deepseek-reasoner" if (settings.get("provider") == "deepseek" and complex_flag) else planner_model
    llm = make_llm(model_override=planner_model_name, temperature=0)
    
    has_data = "Yes" if state.get("market_data") else "No"
    data_failed = bool(state.get("data_failed"))
    has_code = "Yes" if state.get("strategy_code") else "No"
    
    exec_output = state.get("execution_output", "")
    metrics = state.get("performance_metrics")
    has_metrics = "Yes" if metrics else "No"
    analysis_completed_flag = bool(state.get("analysis_completed"))
    analysis_completed = "Yes" if analysis_completed_flag else "No"
    analysis_runs = state.get("analysis_runs", 0) or 0
    
    retry_count = state.get("retry_count", 0)
    
    # Heuristic/LLM Decision Logic
    # We use an LLM to make the decision dynamic and "reflective"
    
    system_prompt = """You are the Manager and Planner of a quantitative trading platform.
    Your goal is to fulfill the user's request by orchestrating the following agents:
    
    1. `data_agent`: Fetches market data. (Requires: Ticker symbol)
    2. `quant_agent`: Generates Python strategy code. (Requires: Market Data)
    3. `exec_agent`: Executes the strategy code. (Requires: Strategy Code)
    4. `analyst_agent`: Analyzes the backtest results. (Requires: Execution Metrics)
    
    Current Status:
    - Data Available: {has_data}
    - Code Available: {has_code}
    - Execution Metrics Available: {has_metrics}
    - Analysis Completed: {analysis_completed}
    - Analyst Runs: {analysis_runs}
    - Retry Count: {retry_count}
    
    Last Execution Output (if any):
    {exec_output}
    
    User Request:
    {user_input}

    Detected Intent: {intent_label} (data_query | quant_strategy | macro | valuation | news_info | other)
    Flags from intent extraction:
    - need_full_history: {need_full_history}
    - needs_benchmark: {needs_benchmark}
    
     Decision Logic:
     1. **Analyze User Intent**:
         - If the user ONLY wants to fetch/see data (e.g., "Show me the price of AAPL", "Get data for 600519"), you DO NOT need `quant_agent` or `exec_agent`.
         - If the user wants to BACKTEST a strategy (e.g., "Run a moving average strategy", "Backtest RSI"), you need the full pipeline.
    
     2. **Step Selection (intent-aware)**:
         - If intent is `news_info`: politely reply in Chinese that the systemä¸“æ³¨è¡Œæƒ…/å›æµ‹ï¼Œä¸æä¾›èµ„è®¯æŠ“å–ï¼Œå¹¶æç¤ºç”¨æˆ·ç»™å‡ºå…·ä½“æ•°æ®/å›æµ‹éœ€æ±‚ï¼›then `FINISH`.
         - If intent is `other`: reply briefly in Chinese thatå½“å‰èƒ½åŠ›èšç„¦è¡Œæƒ…ã€å›æµ‹ã€ç­–ç•¥ï¼Œè¯·æä¾›ç›¸å…³è¯·æ±‚ï¼›then `FINISH`.
         - If intent is `macro`: call `macro_agent` forå®è§‚åˆ†æï¼›å¦‚éœ€è¡¥å……ä¿¡æ¯å¯åœ¨ Reasoning è¯´æ˜ã€‚
         - If intent is `valuation`: å¦‚æœç¼ºå°‘æ•°æ®å…ˆè°ƒç”¨ `data_agent` è·å–è¡Œæƒ…ï¼›è‹¥å·²æœ‰æ•°æ®ï¼Œè°ƒç”¨ `valuation_agent` åšä¼°å€¼ç›¸å¯¹ä½ç½®åˆ†æã€‚
         - If intent is `data_query`:
             - If Data is missing, call `data_agent`.
             - If Data is present and no backtest is asked, give a concise Chinese reply (å¯æé†’å¯è§†åŒ–/æŒ‡æ ‡éœ€æ±‚) and `FINISH`.
         - If intent is `quant_strategy` (å«ç»„åˆ/æŒ‡æ ‡/ç­–ç•¥/å›æµ‹):
             - If Data is missing, call `data_agent`.
             - If Data is present and Code is missing, call `quant_agent`.
             - If Code is present but Metrics are missing, call `exec_agent`.
             - If Execution failed, call `quant_agent` (retry).
             - If Execution succeeded and the user expects interpretation, call `analyst_agent`.
    
     3. **Termination**:
         - Provide the final answer and return `FINISH` once the user's goal is satisfied, regardless of whether the analyst was used.
         - Only call `analyst_agent` when deeper or more specialized analysis adds value.
         - Only call `analyst_agent` again if you clearly explain in Reasoning why deeper analysis or revisions are required.
         - If Retry Count > 3, return `FINISH`.
    
     4. **Final Reply**:
         - When you choose `FINISH`, include a short, user-facing answer in Chinese after `FinalResponse:`.
         - When you choose another agent, set `FinalResponse` to `N/A`.
    
    Return your response in the following format:
    Reasoning: <ç”¨ä¸­æ–‡ï¼Œç®€æ´è¯´æ˜å†³ç­–ï¼Œå¿…é¡»åŒ…å«ï¼šç”¨æˆ·éœ€æ±‚æ¦‚è¦ã€åˆ¤å®šçš„ intentã€need_full_history/needs_benchmark æ ‡å¿—ã€å½“å‰å·²æœ‰/ç¼ºå°‘çš„æ•°æ®æˆ–ä»£ç ã€ä¸ºä½•é€‰æ‹©è¯¥ä¸‹ä¸€æ­¥>
    Decision: <Next Agent Name or FINISH>
    FinalResponse: <Your final answer if Decision is FINISH, otherwise N/A>
    """
    
    prompt = ChatPromptTemplate.from_messages([
        ("system", system_prompt),
        ("user", "What is the next step?")
    ])
    
    chain = prompt | llm
    
    input_vars = {
        "has_data": has_data,
        "has_code": has_code,
        "has_metrics": has_metrics,
        "analysis_completed": analysis_completed,
        "analysis_runs": analysis_runs,
        "retry_count": retry_count,
        "exec_output": exec_output[-200:] if exec_output else "None", # shorter for speed
        "user_input": user_input,
        "intent_label": intent_label,
        "need_full_history": need_full_history_flag,
        "needs_benchmark": needs_benchmark_flag,
    }

    # --- Intent/early handling ---
    if data_failed:
        reasoning = "æ•°æ®è·å–å¤±è´¥ï¼Œç»ˆæ­¢å¹¶æç¤ºç”¨æˆ·æ£€æŸ¥ä»£ç /å…¬å¸åã€‚"
        return {
            "next_step": "FINISH",
            "retry_count": retry_count,
            "sender": "planner_agent",
            "reasoning": reasoning,
            "analysis_completed": analysis_completed_flag,
            "analysis_runs": analysis_runs,
            "force_agent": None,
            **flag_payload,
            "messages": [AIMessage(content="è¡Œæƒ…è·å–å¤±è´¥ï¼Œè¯·æ£€æŸ¥è‚¡ç¥¨/æŒ‡æ•°ä»£ç æˆ–å…¬å¸åæ˜¯å¦æ­£ç¡®ã€‚")],
            "llm_interaction": {
                "input": {k: ('***MASKED***' if any(x in k.lower() for x in ['token','api_key','secret','password']) else v) for k, v in input_vars.items()},
                "prompt": "<skipped - data failed>",
                "response": "<data_failed>"
            }
        }

    if intent_label == "news_info":
        reasoning = "æ„å›¾ä¸ºèµ„è®¯/æ–°é—»æŸ¥è¯¢ï¼Œå½“å‰ç³»ç»Ÿä¸“æ³¨è¡Œæƒ…ã€å›æµ‹å’Œç­–ç•¥ï¼Œä¸æŠ“å–èµ„è®¯ã€‚"
        return {
            "next_step": "FINISH",
            "retry_count": retry_count,
            "sender": "planner_agent",
            "reasoning": reasoning,
            "analysis_completed": analysis_completed_flag,
            "analysis_runs": analysis_runs,
            **flag_payload,
            "messages": [AIMessage(content="å½“å‰å¹³å°ä¸“æ³¨è¡Œæƒ…ã€å›æµ‹å’Œç­–ç•¥ï¼Œä¸æä¾›èµ„è®¯æŠ“å–ã€‚è¯·æä¾›å…·ä½“çš„è¡Œæƒ…æˆ–å›æµ‹éœ€æ±‚ï¼Œæˆ‘ä¼šç»§ç»­å¸®åŠ©ã€‚")],
            "llm_interaction": {
                "input": {k: ('***MASKED***' if any(x in k.lower() for x in ['token','api_key','secret','password']) else v) for k, v in input_vars.items()},
                "prompt": "<skipped - intent guard>",
                "response": "<intent=news_info>"
            }
        }

    if intent_label == "other":
        reasoning = "æ„å›¾ä¸åœ¨æ”¯æŒèŒƒå›´ï¼Œæç¤ºç”¨æˆ·æä¾›è¡Œæƒ…/å›æµ‹ç›¸å…³éœ€æ±‚ã€‚"
        return {
            "next_step": "FINISH",
            "retry_count": retry_count,
            "sender": "planner_agent",
            "reasoning": reasoning,
            "analysis_completed": analysis_completed_flag,
            "analysis_runs": analysis_runs,
            **flag_payload,
            "messages": [AIMessage(content="å½“å‰æ”¯æŒè¡Œæƒ…è·å–ã€é‡åŒ–ç­–ç•¥ä¸å›æµ‹ã€‚å¦‚æœéœ€è¦ï¼Œè¯·è¯´æ˜æ ‡çš„å’Œéœ€æ±‚ã€‚")],
            "llm_interaction": {
                "input": {k: ('***MASKED***' if any(x in k.lower() for x in ['token','api_key','secret','password']) else v) for k, v in input_vars.items()},
                "prompt": "<skipped - intent guard>",
                "response": "<intent=other>"
            }
        }

    if intent_label == "macro":
        reasoning = "æ„å›¾ä¸ºå®è§‚åˆ†æï¼Œè½¬äº¤ macro_agentã€‚"
        return {
            "next_step": "macro_agent",
            "retry_count": retry_count,
            "sender": "planner_agent",
            "reasoning": reasoning,
            "analysis_completed": analysis_completed_flag,
            "analysis_runs": analysis_runs,
            **flag_payload,
            "llm_interaction": {
                "input": {k: ('***MASKED***' if any(x in k.lower() for x in ['token','api_key','secret','password']) else v) for k, v in input_vars.items()},
                "prompt": "<skipped - intent macro>",
                "response": "<intent=macro>"
            }
        }

    if intent_label == "valuation":
        if has_data == "No" and allow_fastpath:
            reasoning = "æ„å›¾ä¸ºä¼°å€¼/æ€§ä»·æ¯”ï¼Œéœ€å…ˆè·å–è¡Œæƒ…æ•°æ®ã€‚"
            return {
                "next_step": "data_agent",
                "retry_count": retry_count,
                "sender": "planner_agent",
                "reasoning": reasoning,
                "analysis_completed": analysis_completed_flag,
                "analysis_runs": analysis_runs,
                **flag_payload,
                "llm_interaction": {
                    "input": {k: ('***MASKED***' if any(x in k.lower() for x in ['token','api_key','secret','password']) else v) for k, v in input_vars.items()},
                    "prompt": "<skipped - valuation needs data>",
                    "response": "<intent=valuation>"
                }
            }
        reasoning = "æ„å›¾ä¸ºä¼°å€¼/æ€§ä»·æ¯”ï¼Œå·²æœ‰æ•°æ®ï¼Œè°ƒç”¨ valuation_agentã€‚"
        return {
            "next_step": "valuation_agent",
            "retry_count": retry_count,
            "sender": "planner_agent",
            "reasoning": reasoning,
            "analysis_completed": analysis_completed_flag,
            "analysis_runs": analysis_runs,
            **flag_payload,
            "llm_interaction": {
                "input": {k: ('***MASKED***' if any(x in k.lower() for x in ['token','api_key','secret','password']) else v) for k, v in input_vars.items()},
                "prompt": "<skipped - intent valuation>",
                "response": "<intent=valuation>"
            }
        }

    # --- Early-stop heuristic (skip LLM for obvious routes) ---
    if allow_fastpath and has_data == "No":
        decision = "data_agent"
        reasoning = "ç¼ºå°‘è¡Œæƒ…æ•°æ®ï¼Œå…ˆè°ƒç”¨ data_agent è·å–æ•°æ®ã€‚"
        update = {
            "next_step": decision,
            "retry_count": retry_count,
            "sender": "planner_agent",
            "reasoning": reasoning,
            "analysis_completed": analysis_completed_flag,
            "analysis_runs": analysis_runs,
            **flag_payload,
            "llm_interaction": {
                "input": {k: ('***MASKED***' if any(x in k.lower() for x in ['token','api_key','secret','password']) else v) for k, v in input_vars.items()},
                "prompt": "<skipped - early rule>",
                "response": "<skipped - early rule>"
            }
        }
        return update

    # If user only wants data/quick analysis and data is ready, finish with a short reply
    if allow_fastpath and intent_label == "data_query" and has_data == "Yes":
        if interpret_request:
            reasoning = "ç”¨æˆ·è¦æ±‚è§£è¯»/åˆ†æå·²æœ‰è¡Œæƒ…æ•°æ®ï¼Œè½¬äº¤ analyst_agent åšæ•°æ®æ¦‚è§ˆä¸è§£è¯»ã€‚"
            return {
                "next_step": "analyst_agent",
                "retry_count": retry_count,
                "sender": "planner_agent",
                "reasoning": reasoning,
                "analysis_completed": analysis_completed_flag,
                "analysis_runs": analysis_runs,
                **flag_payload,
                "llm_interaction": {
                    "input": {k: ('***MASKED***' if any(x in k.lower() for x in ['token','api_key','secret','password']) else v) for k, v in input_vars.items()},
                    "prompt": "<skipped - data interpret>",
                    "response": "<intent=data_query, route=analyst>"
                }
            }
        reasoning = "ç”¨æˆ·æ„å›¾ä¸ºè¡Œæƒ…/å•æ ‡çš„æŸ¥è¯¢ï¼Œæ•°æ®å·²å…·å¤‡ï¼Œç›´æ¥å›å¤å³å¯ã€‚"
        return {
            "next_step": "FINISH",
            "retry_count": retry_count,
            "sender": "planner_agent",
            "reasoning": reasoning,
            "analysis_completed": analysis_completed_flag,
            "analysis_runs": analysis_runs,
            "need_full_history": need_full_history_flag,
            "needs_benchmark": needs_benchmark_flag,
            "messages": [AIMessage(content="è¡Œæƒ…æ•°æ®å·²è·å–ã€‚å¦‚éœ€æŒ‡æ ‡/å›¾è¡¨/å›æµ‹ï¼Œè¯·å‘ŠçŸ¥å…·ä½“éœ€æ±‚ã€‚")],
            "llm_interaction": {
                "input": {k: ('***MASKED***' if any(x in k.lower() for x in ['token','api_key','secret','password']) else v) for k, v in input_vars.items()},
                "prompt": "<skipped - data intent finish>",
                "response": "<intent=data_query>"
            }
        }

    if allow_fastpath and has_code == "No":
        decision = "quant_agent"
        reasoning = "å·²æœ‰æ•°æ®ä½†ç¼ºå°‘ç­–ç•¥ä»£ç ï¼Œè°ƒç”¨ quant_agent ç”Ÿæˆä»£ç ã€‚"
        update = {
            "next_step": decision,
            "retry_count": retry_count,
            "sender": "planner_agent",
            "reasoning": reasoning,
            "analysis_completed": analysis_completed_flag,
            "analysis_runs": analysis_runs,
            **flag_payload,
            "llm_interaction": {
                "input": {k: ('***MASKED***' if any(x in k.lower() for x in ['token','api_key','secret','password']) else v) for k, v in input_vars.items()},
                "prompt": "<skipped - early rule>",
                "response": "<skipped - early rule>"
            }
        }
        return update

    if allow_fastpath and has_metrics == "No":
        decision = "exec_agent"
        reasoning = "å·²æœ‰æ•°æ®å’Œä»£ç ï¼Œä½†ç¼ºå°‘å›æµ‹æŒ‡æ ‡ï¼Œè°ƒç”¨ exec_agent æ‰§è¡Œå›æµ‹ã€‚"
        update = {
            "next_step": decision,
            "retry_count": retry_count,
            "sender": "planner_agent",
            "reasoning": reasoning,
            "analysis_completed": analysis_completed_flag,
            "analysis_runs": analysis_runs,
            **flag_payload,
            "llm_interaction": {
                "input": {k: ('***MASKED***' if any(x in k.lower() for x in ['token','api_key','secret','password']) else v) for k, v in input_vars.items()},
                "prompt": "<skipped - early rule>",
                "response": "<skipped - early rule>"
            }
        }
        return update

    # --- Simple cache key to avoid repeated LLM calls on identical state ---
    cache_key = (
        has_data,
        has_code,
        has_metrics,
        analysis_completed,
        analysis_runs,
        retry_count,
        user_input.strip()[:200],
        complex_flag,
        intent_label,
    )
    if cache_key in _planner_cache:
        return _planner_cache[cache_key]
    
    # Capture formatted messages for debugging/UI
    formatted_messages = prompt.format_messages(**input_vars)
    formatted_prompt = "\n\n".join([f"**{m.type.upper()}**: {m.content}" for m in formatted_messages])
    
    with st.expander("ğŸ§­ Planner Agent", expanded=True):
        timer = render_live_timer("â³ Planner is thinking...")
        response = chain.invoke(input_vars)
        timer.empty() # Clear timer when done
        
        display_token_usage(response)
        
        with st.expander("ğŸ§  View Raw Prompt & Response", expanded=False):
            st.markdown("**ğŸ“ Prompt:**")
            st.code(formatted_prompt, language="markdown")
            st.markdown("**ğŸ’¬ Response:**")
            st.code(response.content, language="text")
        
        content = response.content.strip()

        final_response = ""
        decision_text = content
        if "FinalResponse:" in content:
            decision_text, final_response_section = content.split("FinalResponse:", 1)
            final_response = final_response_section.strip()

        reasoning = ""
        decision = "FINISH"

        if "Decision:" in decision_text:
            parts = decision_text.split("Decision:")
            reasoning = parts[0].replace("Reasoning:", "").strip()
            decision = parts[1].strip().replace("'", "").replace('"', "")
        else:
            # Fallback if format is not followed
            decision = decision_text.replace("'", "").replace('"', "")
            reasoning = "No reasoning provided."
        
        # Basic validation of decision
        valid_agents = ["data_agent", "quant_agent", "exec_agent", "analyst_agent", "macro_agent", "valuation_agent", "FINISH"]
        if decision not in valid_agents:
            # Fallback logic if LLM hallucinates
            if has_data == "No": decision = "data_agent"
            elif has_code == "No": decision = "quant_agent"
            elif has_metrics == "No": decision = "exec_agent"
            else: decision = "analyst_agent"

        if decision == "analyst_agent" and analysis_runs > 0:
            followup_keywords = ["è¿›ä¸€æ­¥", "æ·±å…¥", "å¤ç›˜", "è¡¥å……", "ä¸æ»¡æ„", "é‡æ–°åˆ†æ", "æ›´è¯¦ç»†", "follow", "å†åˆ†æ"]
            needs_followup = any(keyword in reasoning for keyword in followup_keywords)
            if needs_followup:
                analysis_completed_flag = False
            else:
                decision = "FINISH"
                final_response = final_response or reasoning

        normalized_final = final_response.strip().lower()
        if normalized_final in {"", "n/a", "na", "none", "null", "æ— ", "æš‚æ— "}:
            final_response = ""
            
        print(f"Planner Decision: {decision}")
        
        st.markdown(f"**Reasoning:** {reasoning}")
        st.markdown(f"**Decision:** `{decision}`")
        if final_response:
            st.markdown(f"**Final Response:** {final_response}")
    
    # If retrying, increment counter
    if decision == "quant_agent" and has_code == "Yes":
        retry_count += 1
    
    update = {
        "next_step": decision,
        "retry_count": retry_count,
        "sender": "planner_agent",
        "reasoning": reasoning,
        "analysis_completed": analysis_completed_flag,
        "analysis_runs": analysis_runs,
        **flag_payload,
        "llm_interaction": {
            "input": {k: ('***MASKED***' if any(x in k.lower() for x in ['token','api_key','secret','password']) else v) for k, v in input_vars.items()},
            "prompt": formatted_prompt,
            "response": content
        }
    }

    if final_response and decision == "FINISH":
        update["messages"] = [AIMessage(content=final_response)]

    return update
