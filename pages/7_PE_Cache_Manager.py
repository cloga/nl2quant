"""PEæ•°æ®ç¼“å­˜ç®¡ç†é¡µé¢

åŠŸèƒ½ï¼š
1. æ˜¾ç¤ºç¼“å­˜çŠ¶æ€å’Œæ›´æ–°æ—¥æœŸ
2. å¼‚æ­¥è§¦å‘å…¨é‡æ›´æ–°
3. å®æ—¶æ˜¾ç¤ºæ›´æ–°è¿›åº¦
4. å¯¼å‡ºç¼“å­˜æ•°æ®åˆ°CSV
"""

import sys
import threading
from datetime import datetime
from pathlib import Path

import pandas as pd
import streamlit as st
import tushare as ts
from dotenv import load_dotenv

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
ROOT = Path(__file__).resolve().parent.parent
if str(ROOT) not in sys.path:
    sys.path.insert(0, str(ROOT))

from app.data.pe_cache import PECache, batch_compute_and_cache, export_cache_to_csv


st.set_page_config(
    page_title="PEæ•°æ®ç¼“å­˜ç®¡ç†",
    page_icon="ğŸ’¾",
    layout="wide"
)

st.title("ğŸ’¾ PEæ•°æ®ç¼“å­˜ç®¡ç†")

# åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
if "update_running" not in st.session_state:
    st.session_state.update_running = False
if "progress" not in st.session_state:
    st.session_state.progress = {"current": 0, "total": 0, "ts_code": "", "status": ""}


# åŠ è½½ç¼“å­˜ä¿¡æ¯
cache = PECache()
metadata = cache.get_metadata()

# æ˜¾ç¤ºç¼“å­˜çŠ¶æ€
col1, col2, col3 = st.columns(3)

with col1:
    st.metric("ç¼“å­˜è®°å½•æ•°", metadata.get("total_stocks", 0))

with col2:
    last_update = metadata.get("last_update", "æœªæ›´æ–°")
    st.metric("æœ€åæ›´æ–°æ—¶é—´", last_update)

with col3:
    is_fresh = cache.is_cache_fresh(max_age_days=1)
    status = "âœ… æ–°é²œ" if is_fresh else "âš ï¸ éœ€è¦æ›´æ–°"
    st.metric("ç¼“å­˜çŠ¶æ€", status)

st.divider()

# æ›´æ–°é€‰é¡¹
st.subheader("ğŸ“Š æ•°æ®æ›´æ–°")

col_opt1, col_opt2 = st.columns(2)

with col_opt1:
    force_update = st.checkbox(
        "å¼ºåˆ¶å…¨é‡æ›´æ–°",
        help="å‹¾é€‰åå°†å¿½ç•¥ç¼“å­˜ï¼Œé‡æ–°è®¡ç®—æ‰€æœ‰è‚¡ç¥¨çš„PEæ•°æ®"
    )

with col_opt2:
    limit = st.number_input(
        "é™åˆ¶è‚¡ç¥¨æ•°é‡ï¼ˆæµ‹è¯•ç”¨ï¼‰",
        min_value=0,
        max_value=10000,
        value=0,
        help="ä»…ç”¨äºæµ‹è¯•ï¼Œ0è¡¨ç¤ºä¸é™åˆ¶"
    )

st.divider()


def progress_callback(current, total, ts_code, status):
    """è¿›åº¦å›è°ƒå‡½æ•°"""
    st.session_state.progress = {
        "current": current,
        "total": total,
        "ts_code": ts_code,
        "status": status
    }


def run_update_task(ts_codes, force_update):
    """åå°æ›´æ–°ä»»åŠ¡"""
    try:
        batch_compute_and_cache(
            ts_codes=ts_codes,
            force_update=force_update,
            use_batch_daily=True,
            progress_callback=progress_callback
        )
    finally:
        st.session_state.update_running = False


# æ›´æ–°æŒ‰é’®
col_btn1, col_btn2, col_btn3 = st.columns(3)

with col_btn1:
    if st.button(
        "ğŸš€ å¼€å§‹æ›´æ–°",
        disabled=st.session_state.update_running,
        type="primary",
        use_container_width=True
    ):
        # è·å–è‚¡ç¥¨åˆ—è¡¨
        load_dotenv()
        pro = ts.pro_api()
        
        with st.spinner("è·å–è‚¡ç¥¨åˆ—è¡¨..."):
            df_basic = pro.stock_basic(
                exchange='',
                list_status='L',
                fields='ts_code,symbol,name,list_date'
            )
            
            # ä»…ä¿ç•™ä¸Šå¸‚â‰¥5å¹´çš„è‚¡ç¥¨
            now = datetime.now()
            cutoff_str = f"{now.year - 5}{now.strftime('%m%d')}"
            df_basic = df_basic.copy()
            df_basic["list_date"] = df_basic["list_date"].astype(str).fillna("")
            df_basic = df_basic[df_basic["list_date"].str.len() == 8]
            df_basic = df_basic[df_basic["list_date"] <= cutoff_str]
            
            if limit > 0:
                df_basic = df_basic.head(limit)
            
            ts_codes = df_basic["ts_code"].tolist()
            st.info(f"å°†æ›´æ–° {len(ts_codes)} åªè‚¡ç¥¨çš„PEæ•°æ®")
        
        # å¯åŠ¨åå°çº¿ç¨‹
        st.session_state.update_running = True
        st.session_state.progress = {"current": 0, "total": len(ts_codes), "ts_code": "", "status": ""}
        
        thread = threading.Thread(
            target=run_update_task,
            args=(ts_codes, force_update),
            daemon=True
        )
        thread.start()
        st.rerun()

with col_btn2:
    if st.button(
        "ğŸ’¾ å¯¼å‡ºåˆ°CSV",
        use_container_width=True
    ):
        output_file = f"data/pe_ratios_cache_{datetime.now().strftime('%Y%m%d')}.csv"
        with st.spinner("å¯¼å‡ºä¸­..."):
            export_cache_to_csv(output_file)
        st.success(f"å¯¼å‡ºæˆåŠŸ: {output_file}")

with col_btn3:
    if st.button(
        "ğŸ”„ åˆ·æ–°çŠ¶æ€",
        use_container_width=True
    ):
        st.rerun()

# æ˜¾ç¤ºè¿›åº¦
if st.session_state.update_running:
    st.divider()
    st.subheader("â³ æ›´æ–°è¿›åº¦")
    
    progress = st.session_state.progress
    current = progress.get("current", 0)
    total = progress.get("total", 1)
    ts_code = progress.get("ts_code", "")
    status = progress.get("status", "")
    
    # è¿›åº¦æ¡
    progress_pct = current / total if total > 0 else 0
    st.progress(progress_pct, text=f"è¿›åº¦: {current}/{total} ({progress_pct*100:.1f}%)")
    
    # çŠ¶æ€ä¿¡æ¯
    status_text = {
        "cached": "âœ“ ä½¿ç”¨ç¼“å­˜",
        "computed": "ğŸ”„ é‡æ–°è®¡ç®—",
        "error": "âŒ è®¡ç®—å¤±è´¥"
    }.get(status, "â³ å¤„ç†ä¸­")
    
    st.info(f"å½“å‰: {ts_code} - {status_text}")
    
    # è‡ªåŠ¨åˆ·æ–°
    st.empty()
    import time
    time.sleep(0.5)
    st.rerun()

elif st.session_state.progress.get("current", 0) > 0:
    st.success("âœ… æ›´æ–°å®Œæˆï¼")
    if st.button("æ¸…é™¤è¿›åº¦ä¿¡æ¯"):
        st.session_state.progress = {"current": 0, "total": 0, "ts_code": "", "status": ""}
        st.rerun()

st.divider()

# æ˜¾ç¤ºç¼“å­˜æ•°æ®é¢„è§ˆ
st.subheader("ğŸ“‹ ç¼“å­˜æ•°æ®é¢„è§ˆ")

cache_data = cache.load_cache()
if cache_data:
    # è½¬ä¸ºDataFrame
    rows = []
    for ts_code, data in list(cache_data.items())[:100]:  # åªæ˜¾ç¤ºå‰100æ¡
        rows.append(data)
    
    df = pd.DataFrame(rows)
    
    # é€‰æ‹©æ˜¾ç¤ºçš„åˆ—
    display_cols = [
        "ts_code", "trade_date", "close_price", "market_cap",
        "static_pe", "ttm_pe", "linear_extrapolate_pe",
        "forecast_pe_mean", "forecast_pe_median"
    ]
    df_display = df[[col for col in display_cols if col in df.columns]]
    
    st.dataframe(df_display, use_container_width=True, height=400)
    
    if len(cache_data) > 100:
        st.info(f"æ˜¾ç¤ºå‰100æ¡è®°å½•ï¼Œå…± {len(cache_data)} æ¡")
else:
    st.warning("ç¼“å­˜ä¸ºç©ºï¼Œè¯·å…ˆæ‰§è¡Œæ•°æ®æ›´æ–°")

# é¡µé¢è¯´æ˜
with st.expander("â„¹ï¸ ä½¿ç”¨è¯´æ˜"):
    st.markdown("""
    ### åŠŸèƒ½è¯´æ˜
    
    1. **ç¼“å­˜çŠ¶æ€**: æ˜¾ç¤ºå½“å‰ç¼“å­˜çš„è®°å½•æ•°å’Œæ›´æ–°æ—¶é—´
    2. **æ•°æ®æ›´æ–°**: 
       - é»˜è®¤å¢é‡æ›´æ–°ï¼ˆè·³è¿‡å·²ç¼“å­˜çš„è‚¡ç¥¨ï¼‰
       - å‹¾é€‰"å¼ºåˆ¶å…¨é‡æ›´æ–°"å°†é‡æ–°è®¡ç®—æ‰€æœ‰è‚¡ç¥¨
       - "é™åˆ¶è‚¡ç¥¨æ•°é‡"ç”¨äºå°è§„æ¨¡æµ‹è¯•
    3. **å¯¼å‡ºCSV**: å°†ç¼“å­˜æ•°æ®å¯¼å‡ºä¸ºCSVæ–‡ä»¶ï¼Œä¾¿äºåˆ†æ
    
    ### ä¼˜åŒ–è¯´æ˜
    
    - **æ‰¹é‡è·å–è¡Œæƒ…**: ä¸€æ¬¡æ€§è·å–æ‰€æœ‰è‚¡ç¥¨çš„ daily_basic æ•°æ®ï¼Œå‡å°‘ç½‘ç»œè¯·æ±‚
    - **æœ¬åœ°ç¼“å­˜**: è®¡ç®—ç»“æœä¿å­˜åœ¨ `data/cache/pe_cache.json`
    - **å¢é‡æ›´æ–°**: ä»…è®¡ç®—æ–°å¢æˆ–éœ€è¦æ›´æ–°çš„è‚¡ç¥¨
    - **å¼‚æ­¥æ›´æ–°**: åå°çº¿ç¨‹æ‰§è¡Œæ›´æ–°ï¼Œä¸é˜»å¡é¡µé¢æ“ä½œ
    
    ### æ³¨æ„äº‹é¡¹
    
    - å…¨é‡æ›´æ–°çº¦5000åªè‚¡ç¥¨å¯èƒ½éœ€è¦1-2å°æ—¶ï¼ˆå–å†³äºç½‘ç»œå’ŒTushareé™æµï¼‰
    - æ›´æ–°æœŸé—´å¯ä»¥æŸ¥çœ‹å®æ—¶è¿›åº¦
    - å»ºè®®æ¯æ—¥æ›´æ–°ä¸€æ¬¡å³å¯
    """)
